---
permalink: /
title: "Yi Xiao personal websites"
layout: single
author_profile: true
header:
  show_title: false
---


About me
======
I am a Ph.D. candidate in Computer Science and a research associate in Laboratory for Ubiquitous and Intelligent Sensing (UIS Lab) at Arizona State University since Fall 2021. I am honored to be advised by Dr. Asif Salekin. My research focuses on developing AI-driven systems for wearable systems for health related applications. By integrating advanced techniques such as large language models (LLMs), vision-language models (VLMs), multimodal learning, and speech analysis models, I aim to enhance the adaptability, accessibility, and interpretability of smart wearables devices for health monitoring, home management, and personalized interventions. I have published 8 papers in leading AI conferences, including IMWUT, AAAI, InterSpeech, and ICCPS.

Education
======
**Ph.D. in Computer Science**, Arizona State University, Tempe, AZ, USA (Expected 2026)  
**M.S. in Computer Science**, Syracuse University, Syracuse, NY, USA (2021)  
**B.S. in Computer Science and Technology**, Jilin University, Jilin, China (2019)


<h2>ðŸŽ“ Selected Research Experiences</h2>

<table>
  <tr>
    <td style="width: 40%; vertical-align: top;">
      <img src="/images/image1.png" alt="Project 1" width="100%">
    </td>
    <td style="width: 60%; vertical-align: top;">
      <strong>Diffusion model generation for audio mel-spectrogram</strong><br>
      Leverage classifier-generated gradients to guide the diffusion model in generating class-specific, realistic mel-spectrograms, achieving high realism scores.
    </td>
  </tr>
  <tr>
    <td style="vertical-align: top;">
      <img src="/images/image1.png" alt="Project 2" width="100%">
    </td>
    <td style="vertical-align: top;">
      <strong>Optimizing LLM Query Execution in semi-structured Table Question answering.  </strong><br>
      By decomposing questions into image and table components and retrieving relevant data, improves the LLM's EM accuracy by 8.5% on the MultiModalQA dataset.
    </td>
  </tr>
  <tr>
    <td style="vertical-align: top;">
      <img src="/images/image1.png" alt="Project 3" width="100%">
    </td>
    <td style="vertical-align: top;">
      <strong>Human Heterogeneity Invariant Stress Sensing.</strong><br>
      Proposed a novel pruning and quantization algorithm that significantly enhances AI model's generalizability, leading to an 7.8% improvement in stress detection accuracy in completely unseen environments.
    </td>
  </tr>

  <tr>
    <td style="vertical-align: top;">
      <img src="/images/image1.png" alt="Project 3" width="100%">
    </td>
    <td style="vertical-align: top;">
      <strong>Reading Between the Heat</strong><br>
      Jointly trained two AI models with cross-modality supervision, where the EDA modality co-teaches the thermal video modality, resulting in over a 10% improvement in the thermal model's accuracy.
    </td>
  </tr>
</table>

Skills
======

* **Programming Languages**: Python, MATLAB, C/C++, Java, SQL,SPSS  
* **Tools & Frameworks**: PyTorch, TensorFlow, NumPy, pandas, scikit-learn, Linux, Docker, Bash, AWS  
* **Deep Learning & ML**: Transformers, Large Language Models (LLMs), Vision-Language Models, Foundation Models, Supervised Fine-Tuning, RLHF, Reinforcement Learning, Self-Supervised Learning, Neural Networks, Multimodal Learning, Statistical Learning  
* **Applications**: Generative AI, Speech Recognition, Natural Language Processing (NLP), Computer Vision, Recommendation Systems, Question Answering, Time Series Forecasting, Face Detection, Clustering, Semantic Search, Sentiment Analysis


<h2>ðŸ“° News</h2>

<div style="display: flex; align-items: flex-start; gap: 20px;">

  <!-- Left Column: Images -->
  <div>
    <img src="/images/image1.png" alt="Image 1" width="120" style="margin-bottom: 10px;">
    <img src="/images/image2.png" alt="Image 2" width="120" style="margin-bottom: 10px;">
    <img src="/images/image3.png" alt="Image 3" width="120">
  </div>

<div>
    <ul>
  <li><strong>2025-07:</strong> Our paper <em>"Human Heterogeneity Invariant Stress Sensing"</em> accepted at <strong>IMWUT/UbiComp 2025</strong> ðŸŽ‰</li>
  <li><strong>2025-05:</strong> Glad to present our work on medical cyber-physical systems track at <strong>CPS-IoT Week 2025, Irvine, CA, USA.</strong></li>
    <li><strong>2025-05:</strong>  Our paper <em>"Psychophysiology-aided Perceptually Fluent Speech Analysis of Children Who Stutter"</em> accepted at <strong>ICCPS 2025</strong>.</li>
  <li><strong>2025-04:</strong> Our paper <em>"CRoP: Context-wise Robust Static Human-Sensing Personalization"</em> accepted at <strong>IMWUT/UbiComp 2025</strong>. ðŸŽ‰</li>
  <li><strong>2024-07:</strong> Our paper on <em>"VeriCompress: A Tool to Streamline the Synthesis of Verified Robust Compressed Neural Networks from Scratch"</em> was accepted at the <strong>AAAI Conference on Artificial Intelligence (AAAI 2024)</strong>.ðŸŽ‰</li>
  <li><strong>2024-10:</strong> My Co-Teaching paper was presented at <strong>UbiComp 2024, Melbourne, Australia.</strong></li>
  <li><strong>2023-10:</strong> Our paper <em>"Reading Between the Heat": Co-Teaching Body Thermal Signatures for Non-intrusive Stress Detection"</em> accepted at <strong>IMWUT/UbiComp 2024</strong> ðŸŽ‰</li>
  <li><strong>2023-10:</strong> Our paper <em>"Classifying Rhoticity of/r/in Speech Sound Disorder using Age-and-Sex Normalized Formants"</em> accepted at <strong>InterSpeech 2024</strong> ðŸŽ‰</li>
  <li><strong>2023-07:</strong> Our paper <em>"Privacy against real-time speech emotion detection via acoustic adversarial evasion of machine learning"</em> accepted at <strong>IMWUT/UbiComp 2023</strong> ðŸŽ‰</li>
  <li><strong>2022-07:</strong> Our paper <em>"Psychophysiological arousal in young children who stutter: An interpretable ai approach."</em> accepted at <strong>IMWUT/UbiComp 2022</strong> ðŸŽ‰</li>
  
   </ul>
  </div>

</div>

Publications
------
1. **<span style="color:#2b6cb0; font-weight:bold;">Xiao, Y.</span>, Sharma, H., Kaur, S., Bergen-Cico, D., Salekin, A.**  
   *[Human Heterogeneity Invariant Stress Sensing](http://arxiv.org/abs/2506.02256)*  
   _Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 2025_

2. **<span style="color:#2b6cb0; font-weight:bold;">Xiao, Y.</span>, Sharma, H., Tumanova, V., Salekin, A.**  
   *[Psychophysiology-aided Perceptually Fluent Speech Analysis of Children Who Stutter](https://dl.acm.org/doi/10.1145/3716550.3722019)*  
   _ACM/IEEE 16th International Conference on Cyber-Physical Systems (CPS-IoT Week 2025), 2025_

3. **<span style="color:#2b6cb0; font-weight:bold;">Xiao, Y.</span>, Sharma, H., Zhang, Z., Bergen-Cico, D., Rahman, T., Salekin, A.**  
   *[Reading Between the Heat: Co-Teaching Body Thermal Signatures for Non-intrusive Stress Detection](https://dl.acm.org/doi/10.1145/3631441)*  
   _Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 2023_

4. **Kaur, S., <span style="color:#2b6cb0; font-weight:bold;">Xiao, Y.</span>, Salekin, A.**  
   *[VeriCompress: A Tool to Streamline the Synthesis of Verified Robust Compressed Neural Networks from Scratch](https://ojs.aaai.org/index.php/AAAI/article/view/30327)*  
   _AAAI Conference on Artificial Intelligence, 2024_

5. **Testa, B., <span style="color:#2b6cb0; font-weight:bold;">Xiao, Y.</span>, Sharma, H., Gump, A., Salekin, A.**  
   *[Privacy against Real-Time Speech Emotion Detection via Acoustic Adversarial Evasion of Machine Learning](https://dl.acm.org/doi/10.1145/3610887)*  
   _Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 2023_

6. **Sharma, H., <span style="color:#2b6cb0; font-weight:bold;">Xiao, Y.</span>, Tumanova, V., Salekin, A.**  
   *[Psychophysiological Arousal in Young Children Who Stutter: An Interpretable AI Approach](https://dl.acm.org/doi/10.1145/3550326)*  
   _Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 2022_

7. **Kaur, S., Gump, A., <span style="color:#2b6cb0; font-weight:bold;">Xiao, Y.</span>, Xin, J., Sharma, H., Benway, N. R., Preston, J. L., Salekin, A.**  
   *[CRoP: Context-wise Robust Static Human-Sensing Personalization](https://dl.acm.org/doi/10.1145/3729483)*  
   _Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 2025_

8. **Benway, N. R., Preston, J. L., Salekin, A., <span style="color:#2b6cb0; font-weight:bold;">Xiao, Y.</span>, Sharma, H., McAllister, T.**  
   *[Classifying Rhoticity of /r/ in Speech Sound Disorder using Age-and-Sex Normalized Formants](http://arxiv.org/abs/2305.16111)*  
   _INTERSPEECH 2023, 2023_

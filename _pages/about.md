---
permalink: /
title: "Yi Xiao personal websites"
layout: single
author_profile: true
header:
  show_title: false
---


About me
======
I am a Ph.D. candidate in Computer Science and a research associate in Laboratory for Ubiquitous and Intelligent Sensing (UIS Lab) at Arizona State University since Fall 2021. I am honored to be advised by Dr. Asif Salekin. My research focuses on developing AI-driven systems for wearable systems for health related applications. By integrating advanced techniques such as large language models (LLMs), vision-language models (VLMs), multimodal learning, and speech analysis models, I aim to enhance the adaptability, accessibility, and interpretability of smart wearables devices for health monitoring, home management, and personalized interventions. I have published 8 papers in leading AI conferences, including IMWUT, AAAI, InterSpeech, and ICCPS.


### Education

<table>
  <tr>
    <td><strong>Arizona State University</strong>, Ph.D. in Computer Science</td>
    <td align="right"><em>Expected 2026</em></td>
  </tr>
  <tr>
    <td><strong>Syracuse University</strong>, M.S. in Computer Science</td>
    <td align="right"><em>2021</em></td>
  </tr>
  <tr>
    <td><strong>Jilin University</strong>, B.S. in Computer Science</td>
    <td align="right"><em>2019</em></td>
  </tr>
</table>


<h2>ðŸ“° News</h2>
<ul>
  <li><strong>2025-07:</strong> Our paper <em>"Human Heterogeneity Invariant Stress Sensing"</em> accepted at <strong>IMWUT/UbiComp 2025</strong> ðŸŽ‰</li>
  <li><strong>2025-05:</strong> Glad to present our work at <strong>COS-IoT Week 2025, Irvine, CA, USA</strong> â€“ <em>"Psychophysiology-aided Perceptually Fluent Speech Analysis of Children Who Stutter"</em>.</li>
  <li><strong>2025-04:</strong> Our paper <em>"CRoP: Context-wise Robust Static Human-Sensing Personalization"</em> accepted at <strong>IMWUT/UbiComp 2025</strong>. ðŸŽ‰</li>
  <li><strong>2024-07:</strong> Our paper on <em>"VeriCompress: A Tool to Streamline the Synthesis of Verified Robust Compressed Neural Networks from Scratch"</em> was accepted at the <strong>AAAI Conference on Artificial Intelligence (AAAI 2024)</strong>.ðŸŽ‰</li>
  <li><strong>2024-10:</strong> My Co-Teaching paper was presented at <strong>UbiComp 2024, Melbourne, Australia.</strong></li>
  <li><strong>2023-10:</strong> Our paper <em>"Reading Between the Heat": Co-Teaching Body Thermal Signatures for Non-intrusive Stress Detection"</em> accepted at <strong>IMWUT/UbiComp 2024</strong> ðŸŽ‰</li>
  <li><strong>2023-10:</strong> Our paper <em>"Classifying Rhoticity of/r/in Speech Sound Disorder using Age-and-Sex Normalized Formants"</em> accepted at <strong>InterSpeech 2024</strong> ðŸŽ‰</li>
  <li><strong>2023-07:</strong> Our paper <em>"Privacy against real-time speech emotion detection via acoustic adversarial evasion of machine learning"</em> accepted at <strong>IMWUT/UbiComp 2023</strong> ðŸŽ‰</li>
  <li><strong>2022-07:</strong> Our paper <em>"Psychophysiological arousal in young children who stutter: An interpretable ai approach."</em> accepted at <strong>IMWUT/UbiComp 2022</strong> ðŸŽ‰</li>
  
</ul>

Selective publications
------
For site content, there is one Markdown file for each type of content, which are stored in directories like _publications, _talks, _posts, _teaching, or _pages. For example, each talk is a Markdown file in the [_talks directory](https://github.com/academicpages/academicpages.github.io/tree/master/_talks). At the top of each Markdown file is structured data in YAML about the talk, which the theme will parse to do lots of cool stuff. The same structured data about a talk is used to generate the list of talks on the [Talks page](https://academicpages.github.io/talks), each [individual page](https://academicpages.github.io/talks/2012-03-01-talk-1) for specific talks, the talks section for the [CV page](https://academicpages.github.io/cv), and the [map of places you've given a talk](https://academicpages.github.io/talkmap.html) (if you run this [python file](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.py) or [Jupyter notebook](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb), which creates the HTML for the map based on the contents of the _talks directory).


